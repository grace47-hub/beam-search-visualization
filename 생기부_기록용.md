# 생기부 기록용 설명 (600자 내외)

## 📌 탐구 제목
LLM 디코딩 결정 시각화 인터페이스 구현 - Greedy Search와 Beam Search 기반 단어 선택 과정의 실시간 시각화

## 🎯 탐구 동기
이전 탐구에서 Beam Search 알고리즘의 번역 품질과 계산 효율을 정량적으로 비교했으나, LLM이 문장을 생성하는 과정에서 어떤 단어 후보들이 유지되거나 제거되는지를 직관적으로 확인하기 어려웠다. 이에 디코딩 과정의 의사결정 구조 자체를 시각적으로 관찰할 수 있는 웹 기반 분석 인터페이스를 직접 구현하고자 하였다.

## 🔬 탐구 방법
Python Streamlit 프레임워크를 활용하여 GPT-2 언어모델의 디코딩 과정을 실시간으로 시각화하는 웹 애플리케이션을 개발하였다. Greedy Search와 Beam Search 알고리즘을 직접 구현하고, 각 생성 단계에서 토큰 확률 분포를 히트맵으로, Beam 후보 경로를 트리 구조로 시각화하였다. 또한 Beam Width 1, 3, 5에 대한 자동 비교 실험 기능을 구현하여 탐색 경로 수, 제거된 후보 수, 최종 확률, 다양성을 정량적으로 비교하였다.

## 📊 탐구 결과
확률 분포가 명확히 수렴하는 일반적인 문장에서는 Beam Width 증가가 최종 결과에 미미한 영향을 미쳤으나, 단어 선택의 확률 차이가 작은 기술 문장에서는 Beam Search가 더 안정적인 선택을 수행함을 확인하였다. 히트맵과 트리 시각화를 통해 각 단계에서 후보가 유지되거나 제거되는 과정을 직접 관찰할 수 있었으며, Beam Search의 역할이 단순한 품질 향상이 아니라 불확실한 선택 구간에서의 결정 안정화임을 시각적으로 입증하였다.

## 💡 탐구 의의
본 탐구는 LLM의 디코딩 과정을 결과 중심이 아닌 의사결정 과정 중심으로 분석하고, 이를 실제로 조작·관찰 가능한 웹 인터페이스로 구현했다는 점에서 의의가 있다. 탐색 알고리즘의 차이를 이론 설명에 그치지 않고 작동하는 시각화 도구를 통해 검증함으로써, AI 시스템의 내부 판단 구조를 비판적으로 이해하는 기반을 마련하였다.

---

## 🎓 생기부 기록 예시 (세특용)

### 정보과학/인공지능 과목

인공지능 탐색 알고리즘을 LLM 문장 생성에 적용한 심화 탐구를 수행함. 이전 연구에서 Beam Search 디코딩의 효과를 정량 분석했으나, 생성 과정 내부의 의사결정 구조가 드러나지 않는 한계를 인식하고, Python Streamlit으로 GPT-2 모델의 디코딩 과정을 실시간 시각화하는 웹 인터페이스를 독자적으로 개발함. Greedy/Beam Search 알고리즘을 직접 구현하고 단계별 토큰 확률을 히트맵으로, 후보 경로를 트리로 시각화하여 탐색 폭 변화에 따른 비용-품질 트레이드오프를 실증함. 단순 결과 비교를 넘어 AI의 내부 판단 과정을 관찰 가능한 형태로 구현한 점에서 설명 가능한 AI 연구에 기여함.

### 수학(확률과 통계) 과목

LLM의 다음 토큰 예측을 조건부 확률 분포로 모델링하고, Greedy Search와 Beam Search 알고리즘의 확률적 의사결정 구조를 분석함. 각 생성 단계에서 상위 N개 토큰의 확률 분포를 히트맵으로 시각화하여 확률 수렴 패턴을 관찰하고, 누적 로그확률을 기준으로 경로를 비교함. Beam Search의 탐색 폭이 증가할 때 탐색 후보 수가 기하급수적으로 증가하나, 최종 확률은 특정 지점 이후 수렴하는 현상을 실험으로 입증하여 확률 이론의 실제 응용 사례를 깊이 있게 탐구함.

---

## 📝 구현 세부사항 (기술 스택)

| 항목 | 내용 |
|------|------|
| **언어** | Python 3.10 |
| **프레임워크** | Streamlit (웹 UI) |
| **모델** | GPT-2 (Hugging Face Transformers) |
| **시각화** | Matplotlib, Graphviz |
| **핵심 기능** | ① Greedy/Beam Search 구현<br>② 토큰 확률 히트맵<br>③ Beam 트리 시각화<br>④ 자동 비교 실험 |
| **코드 규모** | 약 600줄 |

## 🎯 강조 포인트

1. **직접 구현**: 기존 라이브러리 사용이 아닌 알고리즘 자체를 코딩
2. **실제 LLM**: 시뮬레이션이 아닌 GPT-2의 진짜 확률 분포 사용
3. **웹 인터페이스**: CLI가 아닌 사용자 친화적 웹 앱
4. **다층 시각화**: 표, 히트맵, 트리, 그래프 등 다각도 분석
5. **자동화**: 비교 실험을 버튼 하나로 실행

## 💬 예상 질문 & 답변

**Q1. Beam Search를 왜 직접 구현했나요?**
A. 라이브러리의 블랙박스 함수를 사용하면 내부 과정(후보 유지/제거)을 관찰할 수 없기 때문입니다. 직접 구현해야 각 단계의 상태를 추출하고 시각화할 수 있습니다.

**Q2. 왜 한국어가 아닌 영어 모델을 사용했나요?**
A. GPT-2는 영어로 학습되어 안정적이고, 한국어 모델은 추가 설정이 복잡하여 1주일 내 완성을 위해 영어를 선택했습니다.

**Q3. Beam Width를 늘리면 항상 더 좋은 결과가 나오나요?**
A. 아닙니다. 실험 결과, 확률이 명확히 수렴하는 경우 width 증가는 계산 비용만 늘릴 뿐 품질 개선이 미미했습니다. 불확실한 선택 구간에서만 효과적이었습니다.

**Q4. 이 연구의 실용적 가치는 무엇인가요?**
A. ① 탐색 알고리즘 교육용 도구, ② 설명 가능한 AI 연구 기반, ③ 디코딩 파라미터 조정 시 비용-품질 트레이드오프 이해에 기여합니다.

**Q5. 후속 연구 계획은?**
A. Temperature, Top-K, Top-P 등 다른 디코딩 전략 추가, 한국어 모델 지원, 그리고 실제 번역 태스크에 적용하여 품질 개선 실험을 진행하고 싶습니다.
